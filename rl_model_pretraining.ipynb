{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02fd673-f85f-479c-9de9-83abdf716b95",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001bdb23-0dd6-469d-9aac-5310324b8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:50:13.575827: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-09 11:50:13.575873: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-09 11:50:13.575884: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-09 11:50:13.735366: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "## General\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## In order to run calculations on AWS GPU, need to explicitly specify CUDA lib directory in the environment variables\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=/home/sagemaker-user/.conda/envs/mlds_gpu\"\n",
    "\n",
    "## Data manipulation and preprocessing\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Modelling\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "## Import DeepCTR code\n",
    "## This is done by cloning the github repository instead of installing with pip. This is because of an incompatibility issue\n",
    "## with TF 2.14 that I had to manually fix in the DeepCTR code\n",
    "deepctr_path = '/home/sagemaker-user/drl-ad-personalization/DeepCTR'\n",
    "if deepctr_path not in sys.path:\n",
    "    sys.path.append(deepctr_path)\n",
    "\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e856153-d5a8-4b2f-8c79-1038b4065536",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc65786-01c5-4c50-9598-3b694bd02914",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c3a5a2-6bb6-4119-aefc-311c0812edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:50:22.131804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.480473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.482353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.486505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.488267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.490228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.806890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.809700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.811572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-09 11:50:22.813247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Retrive the pretraining train and validation datasets\n",
    "\n",
    "train_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/train/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")\n",
    "\n",
    "val_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/test/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b93934a-0ae4-4699-943d-917c082d20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the datasets\n",
    "## Define function to derive ctr and split this as the target\n",
    "@tf.function\n",
    "def kdd12_target(element):\n",
    "    features = element.copy()\n",
    "    click = features.pop(key='click')\n",
    "    impression = features.pop(key=\"impression\")\n",
    "    ctr_label = tf.math.divide(click,impression)\n",
    "    return features, ctr_label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_target)\n",
    "val_ds = val_ds.map(kdd12_target)\n",
    "\n",
    "## Create lists of categorical colums for each dataset\n",
    "kdd12_categorical_columns = [\n",
    "    'DisplayURL',\n",
    "    'AdID',\n",
    "    'AdvertiserID',\n",
    "    'QueryID',\n",
    "    'KeywordID',\n",
    "    'TitleID',\n",
    "    'DescriptionID',\n",
    "    'UserID'\n",
    "]\n",
    "\n",
    "# Import categorical feature mappings and define stringloohup objects for each dataset\n",
    "kdd12_stringlookups = {}\n",
    "kdd12_vocab_lengths = {}\n",
    "for field in kdd12_categorical_columns:\n",
    "    df = pd.read_csv(f'./data/kdd12/categorical_value_counts/{field}.csv')\n",
    "    vocab = [elem.encode() for elem in df['field'].astype(str).to_list()]\n",
    "    lookup = StringLookup(vocabulary=vocab, mask_token=None)\n",
    "    kdd12_stringlookups.update({field:lookup})\n",
    "    kdd12_vocab_lengths.update({field:len(vocab)+1})\n",
    "\n",
    "# Define categorical encoding function\n",
    "@tf.function\n",
    "def kdd12_categorical_encoding(features,label):\n",
    "    # Create copy of features, because modifying inputs causes a ValueError\n",
    "    out_features = features.copy()\n",
    "    # Iteratively map the categical feature columns using the corresponging Lookup layer\n",
    "    for f in kdd12_categorical_columns:\n",
    "        lookup = kdd12_stringlookups[f]\n",
    "        out_features[f.lower()] = lookup(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds= train_ds.map(kdd12_categorical_encoding)\n",
    "val_ds = val_ds.map(kdd12_categorical_encoding)\n",
    "\n",
    "\n",
    "# Define numerical feature columns\n",
    "kdd12_numerical_columns = [\n",
    "    'Depth',\n",
    "    'Position'\n",
    "]\n",
    "# Extract scaler dicts for all datasets\n",
    "dist_stats = pd.read_csv('./data/kdd12/means_variances.csv')\n",
    "kdd12_scalers = {}\n",
    "for i in range(len(dist_stats)):\n",
    "    field = dist_stats['field'][i]\n",
    "    mean = dist_stats['mean'][i]\n",
    "    variance = dist_stats['variance'][i]\n",
    "    scaler = Normalization(mean=mean, variance=variance)\n",
    "    scaler.build((1,))\n",
    "    kdd12_scalers.update({field:scaler})\n",
    "\n",
    "# Define scaler functions for all datasets\n",
    "\n",
    "@tf.function\n",
    "def kdd12_numerical_scaling(features,label):\n",
    "    out_features = features.copy()\n",
    "    for f in kdd12_numerical_columns:\n",
    "        scaler = kdd12_scalers[f]\n",
    "        out_features[f.lower()] = scaler(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_numerical_scaling)\n",
    "val_ds = val_ds.map(kdd12_numerical_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc62edca-9b70-4889-a417-fab9c9324b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(100).take(157440).batch(256)\n",
    "val_ds = val_ds.take(39360).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe80505-df39-4b31-a953-db239d3803b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define feature mappings\n",
    "kdd12_fixlen_feature_columns = [SparseFeat(feat.lower(), vocabulary_size=kdd12_vocab_lengths[feat], embedding_dim=4) for feat in kdd12_categorical_columns]\\\n",
    "+ [DenseFeat(feat.lower(),1) for feat in kdd12_numerical_columns]\n",
    "\n",
    "## Generate the dnn and linear feature columns\n",
    "kdd12_dnn_feature_columns = kdd12_fixlen_feature_columns\n",
    "kdd12_linear_feature_columns = kdd12_fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87b85ed-d327-4ea6-b1cb-4efe4921ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=5\n",
    ")\n",
    "# Define the precision, recall and auc metrics\n",
    "precision = tf.keras.metrics.Precision(thresholds=0.5,name='precision')\n",
    "recall = tf.keras.metrics.Recall(thresholds=0.5,name='recall')\n",
    "auc = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "# Define the csvLogger callback\n",
    "csvLogger = CSVLogger('logs/final_rl_model.csv')\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "modelCheckpoint = ModelCheckpoint(\n",
    "    'models/final_rl_model/rl_model.ckpt',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db1df39-6339-4ecb-b205-16502d3d0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model per the hyperparameter tuning\n",
    "model = DCN(\n",
    "    kdd12_linear_feature_columns, \n",
    "    kdd12_dnn_feature_columns, \n",
    "    task='binary',\n",
    "    dnn_hidden_units=[400,300,200],\n",
    "    dnn_dropout=0.6,\n",
    "    l2_reg_dnn=0.005,\n",
    "    l2_reg_linear = 0.005,\n",
    "    l2_reg_embedding=0.005,\n",
    "    dnn_use_bn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf80726-a4e5-42cf-be3d-00a2040b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    \"adam\", \n",
    "    \"binary_crossentropy\", \n",
    "    metrics=[\n",
    "        'binary_crossentropy',\n",
    "        'binary_accuracy',\n",
    "        precision,\n",
    "        recall,\n",
    "        auc\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133bd6e2-e6c0-4d28-bb08-f67d8261bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:51:41.017551: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-09 11:51:43.773352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0d946ada70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-09 11:51:43.773390: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-08-09 11:51:43.800834: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-09 11:51:43.870188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-08-09 11:51:43.994248: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    614/Unknown - 28s 30ms/step - loss: 0.7538 - binary_crossentropy: 0.2178 - binary_accuracy: 0.9383 - precision: 0.0483 - recall: 0.0158 - auc: 0.5514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:52:05.592049: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11792929150690780946\n",
      "2024-08-09 11:52:05.592127: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3344193383366431479\n",
      "2024-08-09 11:52:05.592145: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14869473716482076451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615/615 [==============================] - 34s 41ms/step - loss: 0.7529 - binary_crossentropy: 0.2177 - binary_accuracy: 0.9383 - precision: 0.0483 - recall: 0.0158 - auc: 0.5514 - val_loss: 0.2266 - val_binary_crossentropy: 0.1678 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5855\n",
      "Epoch 2/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.2276 - binary_crossentropy: 0.1839 - binary_accuracy: 0.9523 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5689 - val_loss: 0.2069 - val_binary_crossentropy: 0.1667 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6150\n",
      "Epoch 3/15\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2161 - binary_crossentropy: 0.1802 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5749 - val_loss: 0.2036 - val_binary_crossentropy: 0.1653 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6027\n",
      "Epoch 4/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.2107 - binary_crossentropy: 0.1794 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5686 - val_loss: 0.1948 - val_binary_crossentropy: 0.1653 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6357\n",
      "Epoch 5/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.2071 - binary_crossentropy: 0.1776 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5758 - val_loss: 0.2010 - val_binary_crossentropy: 0.1690 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6265\n",
      "Epoch 6/15\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2059 - binary_crossentropy: 0.1772 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5781 - val_loss: 0.2010 - val_binary_crossentropy: 0.1678 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6305\n",
      "Epoch 7/15\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2027 - binary_crossentropy: 0.1769 - binary_accuracy: 0.9525 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5753 - val_loss: 0.1940 - val_binary_crossentropy: 0.1678 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6212\n",
      "Epoch 8/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.1994 - binary_crossentropy: 0.1762 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5809 - val_loss: 0.1924 - val_binary_crossentropy: 0.1667 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6280\n",
      "Epoch 9/15\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.1973 - binary_crossentropy: 0.1752 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5874 - val_loss: 0.1910 - val_binary_crossentropy: 0.1670 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6288\n",
      "Epoch 10/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.1962 - binary_crossentropy: 0.1752 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5865 - val_loss: 0.1873 - val_binary_crossentropy: 0.1649 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6307\n",
      "Epoch 11/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1949 - binary_crossentropy: 0.1749 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5878 - val_loss: 0.1875 - val_binary_crossentropy: 0.1663 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6315\n",
      "Epoch 12/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.1930 - binary_crossentropy: 0.1747 - binary_accuracy: 0.9525 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5878 - val_loss: 0.1857 - val_binary_crossentropy: 0.1656 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6300\n",
      "Epoch 13/15\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.1909 - binary_crossentropy: 0.1739 - binary_accuracy: 0.9525 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5945 - val_loss: 0.1817 - val_binary_crossentropy: 0.1652 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6288\n",
      "Epoch 14/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1896 - binary_crossentropy: 0.1738 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5948 - val_loss: 0.1821 - val_binary_crossentropy: 0.1641 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6340\n",
      "Epoch 15/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1884 - binary_crossentropy: 0.1736 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5965 - val_loss: 0.1822 - val_binary_crossentropy: 0.1645 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0e8015cf70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=256,\n",
    "    epochs=15,\n",
    "    callbacks=[\n",
    "        csvLogger,\n",
    "        modelCheckpoint,\n",
    "        earlystopping\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlds_gpu)",
   "language": "python",
   "name": "mlds_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
