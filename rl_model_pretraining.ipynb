{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02fd673-f85f-479c-9de9-83abdf716b95",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001bdb23-0dd6-469d-9aac-5310324b8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 08:43:30.341490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-16 08:43:30.341534: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-16 08:43:30.341545: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-16 08:43:30.617109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "## General\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## In order to run calculations on AWS GPU, need to explicitly specify CUDA lib directory in the environment variables\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=/home/sagemaker-user/.conda/envs/mlds_gpu\"\n",
    "\n",
    "## Data manipulation and preprocessing\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Modelling\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "## Import DeepCTR code\n",
    "## This is done by cloning the github repository instead of installing with pip. This is because of an incompatibility issue\n",
    "## with TF 2.14 that I had to manually fix in the DeepCTR code\n",
    "deepctr_path = '/home/sagemaker-user/drl-ad-personalization/DeepCTR'\n",
    "if deepctr_path not in sys.path:\n",
    "    sys.path.append(deepctr_path)\n",
    "\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e856153-d5a8-4b2f-8c79-1038b4065536",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc65786-01c5-4c50-9598-3b694bd02914",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c3a5a2-6bb6-4119-aefc-311c0812edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 08:43:38.397677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:38.707276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:38.709151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:38.713207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:38.714820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:38.716497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:39.018628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:39.021304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:39.022910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-16 08:43:39.024727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Retrive the pretraining train and validation datasets\n",
    "\n",
    "train_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/train/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")\n",
    "\n",
    "val_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/test/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b93934a-0ae4-4699-943d-917c082d20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the datasets\n",
    "## Define function to derive ctr and split this as the target\n",
    "@tf.function\n",
    "def kdd12_target(element):\n",
    "    features = element.copy()\n",
    "    click = features.pop(key='click')\n",
    "    impression = features.pop(key=\"impression\")\n",
    "    ctr_label = tf.where(tf.math.greater_equal(tf.math.divide(click,impression),t),1.,0.)\n",
    "    return features, ctr_label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_target)\n",
    "val_ds = val_ds.map(kdd12_target)\n",
    "\n",
    "## Create lists of categorical colums for each dataset\n",
    "kdd12_categorical_columns = [\n",
    "    'DisplayURL',\n",
    "    'AdID',\n",
    "    'AdvertiserID',\n",
    "    'QueryID',\n",
    "    'KeywordID',\n",
    "    'TitleID',\n",
    "    'DescriptionID',\n",
    "    'UserID'\n",
    "]\n",
    "\n",
    "# Import categorical feature mappings and define stringloohup objects for each dataset\n",
    "kdd12_stringlookups = {}\n",
    "kdd12_vocab_lengths = {}\n",
    "for field in kdd12_categorical_columns:\n",
    "    df = pd.read_csv(f'./data/kdd12/categorical_value_counts/{field}.csv')\n",
    "    vocab = [elem.encode() for elem in df['field'].astype(str).to_list()]\n",
    "    lookup = StringLookup(vocabulary=vocab, mask_token=None)\n",
    "    kdd12_stringlookups.update({field:lookup})\n",
    "    kdd12_vocab_lengths.update({field:len(vocab)+1})\n",
    "\n",
    "# Define categorical encoding function\n",
    "@tf.function\n",
    "def kdd12_categorical_encoding(features,label):\n",
    "    # Create copy of features, because modifying inputs causes a ValueError\n",
    "    out_features = features.copy()\n",
    "    # Iteratively map the categical feature columns using the corresponging Lookup layer\n",
    "    for f in kdd12_categorical_columns:\n",
    "        lookup = kdd12_stringlookups[f]\n",
    "        out_features[f.lower()] = lookup(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds= train_ds.map(kdd12_categorical_encoding)\n",
    "val_ds = val_ds.map(kdd12_categorical_encoding)\n",
    "\n",
    "\n",
    "# Define numerical feature columns\n",
    "kdd12_numerical_columns = [\n",
    "    'Depth',\n",
    "    'Position'\n",
    "]\n",
    "# Extract scaler dicts for all datasets\n",
    "dist_stats = pd.read_csv('./data/kdd12/means_variances.csv')\n",
    "kdd12_scalers = {}\n",
    "for i in range(len(dist_stats)):\n",
    "    field = dist_stats['field'][i]\n",
    "    mean = dist_stats['mean'][i]\n",
    "    variance = dist_stats['variance'][i]\n",
    "    scaler = Normalization(mean=mean, variance=variance)\n",
    "    scaler.build((1,))\n",
    "    kdd12_scalers.update({field:scaler})\n",
    "\n",
    "# Define scaler functions for all datasets\n",
    "\n",
    "@tf.function\n",
    "def kdd12_numerical_scaling(features,label):\n",
    "    out_features = features.copy()\n",
    "    for f in kdd12_numerical_columns:\n",
    "        scaler = kdd12_scalers[f]\n",
    "        out_features[f.lower()] = scaler(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_numerical_scaling)\n",
    "val_ds = val_ds.map(kdd12_numerical_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc62edca-9b70-4889-a417-fab9c9324b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(100).take(157440).batch(256)\n",
    "val_ds = val_ds.take(39360).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe80505-df39-4b31-a953-db239d3803b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define feature mappings\n",
    "kdd12_fixlen_feature_columns = [SparseFeat(feat.lower(), vocabulary_size=kdd12_vocab_lengths[feat], embedding_dim=4) for feat in kdd12_categorical_columns]\\\n",
    "+ [DenseFeat(feat.lower(),1) for feat in kdd12_numerical_columns]\n",
    "\n",
    "## Generate the dnn and linear feature columns\n",
    "kdd12_dnn_feature_columns = kdd12_fixlen_feature_columns\n",
    "kdd12_linear_feature_columns = kdd12_fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87b85ed-d327-4ea6-b1cb-4efe4921ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=5\n",
    ")\n",
    "# Define the precision, recall and auc metrics\n",
    "precision = tf.keras.metrics.Precision(thresholds=0.5,name='precision')\n",
    "recall = tf.keras.metrics.Recall(thresholds=0.5,name='recall')\n",
    "auc = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "# Define the csvLogger callback\n",
    "csvLogger = CSVLogger('logs/final_rl_model.csv')\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "modelCheckpoint = ModelCheckpoint(\n",
    "    'models/final_rl_model/rl_model.ckpt',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db1df39-6339-4ecb-b205-16502d3d0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossNet parameterization: vector\n"
     ]
    }
   ],
   "source": [
    "# Construct the model per the hyperparameter tuning\n",
    "model = DCN(\n",
    "    kdd12_linear_feature_columns, \n",
    "    kdd12_dnn_feature_columns, \n",
    "    task='binary',\n",
    "    dnn_hidden_units=[400,400],\n",
    "    dnn_dropout=0.6,\n",
    "    l2_reg_dnn=0.005,\n",
    "    l2_reg_linear = 0.005,\n",
    "    l2_reg_embedding=0.005,\n",
    "    dnn_use_bn=True,\n",
    "    cross_num=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf80726-a4e5-42cf-be3d-00a2040b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    \"adam\", \n",
    "    \"binary_crossentropy\", \n",
    "    metrics=[\n",
    "        'binary_crossentropy',\n",
    "        'binary_accuracy',\n",
    "        precision,\n",
    "        recall,\n",
    "        auc\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133bd6e2-e6c0-4d28-bb08-f67d8261bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 08:44:58.955429: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-16 08:45:01.556302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f14693a4460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-16 08:45:01.556348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-08-16 08:45:01.597108: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-16 08:45:01.682169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-08-16 08:45:01.813374: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    614/Unknown - 28s 30ms/step - loss: 0.5019 - binary_crossentropy: 0.2095 - binary_accuracy: 0.9427 - precision: 0.0499 - recall: 0.0112 - auc: 0.5567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 08:45:28.480425: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11202395199338273436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615/615 [==============================] - 34s 40ms/step - loss: 0.5015 - binary_crossentropy: 0.2096 - binary_accuracy: 0.9427 - precision: 0.0499 - recall: 0.0112 - auc: 0.5567 - val_loss: 0.2070 - val_binary_crossentropy: 0.1701 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6090\n",
      "Epoch 2/15\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2052 - binary_crossentropy: 0.1787 - binary_accuracy: 0.9523 - precision: 0.0526 - recall: 1.3351e-04 - auc: 0.5880 - val_loss: 0.1921 - val_binary_crossentropy: 0.1673 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6273\n",
      "Epoch 3/15\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.1912 - binary_crossentropy: 0.1716 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6226 - val_loss: 0.1857 - val_binary_crossentropy: 0.1633 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6361\n",
      "Epoch 4/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1893 - binary_crossentropy: 0.1689 - binary_accuracy: 0.9524 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6452 - val_loss: 0.1880 - val_binary_crossentropy: 0.1608 - val_binary_accuracy: 0.9549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6540\n",
      "Epoch 5/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1906 - binary_crossentropy: 0.1672 - binary_accuracy: 0.9525 - precision: 1.0000 - recall: 1.3356e-04 - auc: 0.6593 - val_loss: 0.1917 - val_binary_crossentropy: 0.1615 - val_binary_accuracy: 0.9549 - val_precision: 0.4615 - val_recall: 0.0034 - val_auc: 0.6540\n",
      "Epoch 6/15\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.1911 - binary_crossentropy: 0.1665 - binary_accuracy: 0.9524 - precision: 0.5000 - recall: 2.6709e-04 - auc: 0.6646 - val_loss: 0.1894 - val_binary_crossentropy: 0.1595 - val_binary_accuracy: 0.9548 - val_precision: 0.4286 - val_recall: 0.0034 - val_auc: 0.6624\n",
      "Epoch 7/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1908 - binary_crossentropy: 0.1660 - binary_accuracy: 0.9524 - precision: 0.4286 - recall: 4.0069e-04 - auc: 0.6683 - val_loss: 0.1904 - val_binary_crossentropy: 0.1603 - val_binary_accuracy: 0.9548 - val_precision: 0.4211 - val_recall: 0.0045 - val_auc: 0.6619\n",
      "Epoch 8/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1905 - binary_crossentropy: 0.1657 - binary_accuracy: 0.9524 - precision: 0.4286 - recall: 4.0075e-04 - auc: 0.6710 - val_loss: 0.1898 - val_binary_crossentropy: 0.1604 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6643\n",
      "Epoch 9/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1900 - binary_crossentropy: 0.1654 - binary_accuracy: 0.9524 - precision: 0.5000 - recall: 8.0118e-04 - auc: 0.6734 - val_loss: 0.1894 - val_binary_crossentropy: 0.1602 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6663\n",
      "Epoch 10/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1899 - binary_crossentropy: 0.1652 - binary_accuracy: 0.9524 - precision: 0.5000 - recall: 8.0118e-04 - auc: 0.6744 - val_loss: 0.1893 - val_binary_crossentropy: 0.1601 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6656\n",
      "Epoch 11/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1899 - binary_crossentropy: 0.1649 - binary_accuracy: 0.9524 - precision: 0.5385 - recall: 9.3483e-04 - auc: 0.6765 - val_loss: 0.1897 - val_binary_crossentropy: 0.1602 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6665\n",
      "Epoch 12/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1900 - binary_crossentropy: 0.1647 - binary_accuracy: 0.9525 - precision: 0.5294 - recall: 0.0012 - auc: 0.6772 - val_loss: 0.1900 - val_binary_crossentropy: 0.1602 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6666\n",
      "Epoch 13/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1903 - binary_crossentropy: 0.1645 - binary_accuracy: 0.9524 - precision: 0.4500 - recall: 0.0012 - auc: 0.6789 - val_loss: 0.1905 - val_binary_crossentropy: 0.1601 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6672\n",
      "Epoch 14/15\n",
      "615/615 [==============================] - 23s 38ms/step - loss: 0.1906 - binary_crossentropy: 0.1643 - binary_accuracy: 0.9524 - precision: 0.4545 - recall: 0.0013 - auc: 0.6811 - val_loss: 0.1912 - val_binary_crossentropy: 0.1601 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6681\n",
      "Epoch 15/15\n",
      "615/615 [==============================] - 24s 38ms/step - loss: 0.1910 - binary_crossentropy: 0.1640 - binary_accuracy: 0.9524 - precision: 0.4545 - recall: 0.0013 - auc: 0.6836 - val_loss: 0.1920 - val_binary_crossentropy: 0.1602 - val_binary_accuracy: 0.9548 - val_precision: 0.4500 - val_recall: 0.0051 - val_auc: 0.6683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1628484d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=256,\n",
    "    epochs=15,\n",
    "    callbacks=[\n",
    "        csvLogger,\n",
    "        modelCheckpoint,\n",
    "        earlystopping\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlds_gpu)",
   "language": "python",
   "name": "mlds_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
