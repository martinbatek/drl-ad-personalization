{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02fd673-f85f-479c-9de9-83abdf716b95",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001bdb23-0dd6-469d-9aac-5310324b8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:46:38.549084: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-28 16:46:38.594261: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 16:46:38.594289: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 16:46:38.594298: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 16:46:38.601453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "## General\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## In order to run calculations on AWS GPU, need to explicitly specify CUDA lib directory in the environment variables\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=/home/sagemaker-user/.conda/envs/mlds_gpu\"\n",
    "\n",
    "## Data manipulation and preprocessing\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Modelling\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "## Import DeepCTR code\n",
    "## This is done by cloning the github repository instead of installing with pip. This is because of an incompatibility issue\n",
    "## with TF 2.14 that I had to manually fix in the DeepCTR code\n",
    "deepctr_path = '/home/sagemaker-user/drl-ad-personalization/DeepCTR'\n",
    "if deepctr_path not in sys.path:\n",
    "    sys.path.append(deepctr_path)\n",
    "\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e856153-d5a8-4b2f-8c79-1038b4065536",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc65786-01c5-4c50-9598-3b694bd02914",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c3a5a2-6bb6-4119-aefc-311c0812edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:46:42.866894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:42.903092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:42.904800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:42.907296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:42.908949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:42.910535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:43.089212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:43.090788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:43.092250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-28 16:46:43.093614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Retrive the pretraining train and validation datasets\n",
    "\n",
    "train_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/train/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")\n",
    "\n",
    "val_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"data/kdd12/rl_data/pretraining/test/*\",\n",
    "    batch_size=1,\n",
    "    field_delim=',',\n",
    "    header=True,\n",
    "    column_defaults=['int32','int32','string','string','string','int32','int32','string','string','string','string','string'],\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    compression_type='GZIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b93934a-0ae4-4699-943d-917c082d20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the datasets\n",
    "## Define function to derive ctr and split this as the target\n",
    "@tf.function\n",
    "def kdd12_target(element):\n",
    "    features = element.copy()\n",
    "    click = features.pop(key='click')\n",
    "    impression = features.pop(key=\"impression\")\n",
    "    ctr_label = tf.where(tf.math.greater_equal(tf.math.divide(click,impression),0.5),1.,0.)\n",
    "    return features, ctr_label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_target)\n",
    "val_ds = val_ds.map(kdd12_target)\n",
    "\n",
    "## Create lists of categorical colums for each dataset\n",
    "kdd12_categorical_columns = [\n",
    "    'DisplayURL',\n",
    "    'AdID',\n",
    "    'AdvertiserID',\n",
    "    'QueryID',\n",
    "    'KeywordID',\n",
    "    'TitleID',\n",
    "    'DescriptionID',\n",
    "    'UserID'\n",
    "]\n",
    "\n",
    "# Import categorical feature mappings and define stringloohup objects for each dataset\n",
    "kdd12_stringlookups = {}\n",
    "kdd12_vocab_lengths = {}\n",
    "for field in kdd12_categorical_columns:\n",
    "    df = pd.read_csv(f'./data/kdd12/categorical_value_counts/{field}.csv')\n",
    "    vocab = [elem.encode() for elem in df['field'].astype(str).to_list()]\n",
    "    lookup = StringLookup(vocabulary=vocab, mask_token=None)\n",
    "    kdd12_stringlookups.update({field:lookup})\n",
    "    kdd12_vocab_lengths.update({field:len(vocab)+1})\n",
    "\n",
    "# Define categorical encoding function\n",
    "@tf.function\n",
    "def kdd12_categorical_encoding(features,label):\n",
    "    # Create copy of features, because modifying inputs causes a ValueError\n",
    "    out_features = features.copy()\n",
    "    # Iteratively map the categical feature columns using the corresponging Lookup layer\n",
    "    for f in kdd12_categorical_columns:\n",
    "        lookup = kdd12_stringlookups[f]\n",
    "        out_features[f.lower()] = lookup(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds= train_ds.map(kdd12_categorical_encoding)\n",
    "val_ds = val_ds.map(kdd12_categorical_encoding)\n",
    "\n",
    "\n",
    "# Define numerical feature columns\n",
    "kdd12_numerical_columns = [\n",
    "    'Depth',\n",
    "    'Position'\n",
    "]\n",
    "# Extract scaler dicts for all datasets\n",
    "dist_stats = pd.read_csv('./data/kdd12/means_variances.csv')\n",
    "kdd12_scalers = {}\n",
    "for i in range(len(dist_stats)):\n",
    "    field = dist_stats['field'][i]\n",
    "    mean = dist_stats['mean'][i]\n",
    "    variance = dist_stats['variance'][i]\n",
    "    scaler = Normalization(mean=mean, variance=variance)\n",
    "    scaler.build((1,))\n",
    "    kdd12_scalers.update({field:scaler})\n",
    "\n",
    "# Define scaler functions for all datasets\n",
    "\n",
    "@tf.function\n",
    "def kdd12_numerical_scaling(features,label):\n",
    "    out_features = features.copy()\n",
    "    for f in kdd12_numerical_columns:\n",
    "        scaler = kdd12_scalers[f]\n",
    "        out_features[f.lower()] = scaler(features[f.lower()])\n",
    "    return out_features, label\n",
    "\n",
    "train_ds = train_ds.map(kdd12_numerical_scaling)\n",
    "val_ds = val_ds.map(kdd12_numerical_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc62edca-9b70-4889-a417-fab9c9324b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(100).take(157440).batch(256)\n",
    "val_ds = val_ds.take(39360).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe80505-df39-4b31-a953-db239d3803b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define feature mappings\n",
    "kdd12_fixlen_feature_columns = [SparseFeat(feat.lower(), vocabulary_size=kdd12_vocab_lengths[feat], embedding_dim=4) for feat in kdd12_categorical_columns]\\\n",
    "+ [DenseFeat(feat.lower(),1) for feat in kdd12_numerical_columns]\n",
    "\n",
    "## Generate the dnn and linear feature columns\n",
    "kdd12_dnn_feature_columns = kdd12_fixlen_feature_columns\n",
    "kdd12_linear_feature_columns = kdd12_fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87b85ed-d327-4ea6-b1cb-4efe4921ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=5\n",
    ")\n",
    "# Define the precision, recall and auc metrics\n",
    "precision = tf.keras.metrics.Precision(thresholds=0.5,name='precision')\n",
    "recall = tf.keras.metrics.Recall(thresholds=0.5,name='recall')\n",
    "auc = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "# Define the csvLogger callback\n",
    "csvLogger = CSVLogger('logs/final_rl_model.csv')\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "modelCheckpoint = ModelCheckpoint(\n",
    "    'models/final_rl_model/rl_model.ckpt',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db1df39-6339-4ecb-b205-16502d3d0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossNet parameterization: vector\n"
     ]
    }
   ],
   "source": [
    "# Construct the model per the hyperparameter tuning\n",
    "model = DCN(\n",
    "    kdd12_linear_feature_columns, \n",
    "    kdd12_dnn_feature_columns, \n",
    "    task='binary',\n",
    "    dnn_hidden_units=[400,400,400],\n",
    "    dnn_dropout=0.6,\n",
    "    l2_reg_dnn=0.005,\n",
    "    l2_reg_linear = 0.005,\n",
    "    l2_reg_embedding=0.005,\n",
    "    dnn_use_bn=True,\n",
    "    cross_num=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf80726-a4e5-42cf-be3d-00a2040b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    \"adam\", \n",
    "    \"binary_crossentropy\", \n",
    "    metrics=[\n",
    "        'binary_crossentropy',\n",
    "        'binary_accuracy',\n",
    "        precision,\n",
    "        recall,\n",
    "        auc\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133bd6e2-e6c0-4d28-bb08-f67d8261bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:48:04.920443: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-28 16:48:07.860518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7168eebac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-28 16:48:07.860549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-08-28 16:48:07.865529: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-28 16:48:07.885398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-08-28 16:48:07.978120: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    614/Unknown - 31s 32ms/step - loss: 1.2783 - binary_crossentropy: 0.6807 - binary_accuracy: 0.5991 - precision: 0.0567 - recall: 0.5196 - auc: 0.5822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:48:31.008497: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3714040492661666843\n",
      "2024-08-28 16:48:31.008540: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5634790214675808254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615/615 [==============================] - 37s 43ms/step - loss: 1.2770 - binary_crossentropy: 0.6808 - binary_accuracy: 0.5989 - precision: 0.0568 - recall: 0.5202 - auc: 0.5824 - val_loss: 0.8275 - val_binary_crossentropy: 0.6865 - val_binary_accuracy: 0.5238 - val_precision: 0.0527 - val_recall: 0.6287 - val_auc: 0.6019\n",
      "Epoch 2/25\n",
      "615/615 [==============================] - 25s 41ms/step - loss: 0.4012 - binary_crossentropy: 0.6064 - binary_accuracy: 0.6569 - precision: 0.0680 - recall: 0.5357 - auc: 0.6410 - val_loss: 0.7537 - val_binary_crossentropy: 0.6664 - val_binary_accuracy: 0.5797 - val_precision: 0.0611 - val_recall: 0.6474 - val_auc: 0.6674\n",
      "Epoch 3/25\n",
      "615/615 [==============================] - 26s 41ms/step - loss: 0.3844 - binary_crossentropy: 0.5871 - binary_accuracy: 0.6760 - precision: 0.0748 - recall: 0.5607 - auc: 0.6750 - val_loss: 0.7151 - val_binary_crossentropy: 0.6232 - val_binary_accuracy: 0.6141 - val_precision: 0.0641 - val_recall: 0.6224 - val_auc: 0.6723\n",
      "Epoch 4/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.3879 - binary_crossentropy: 0.5806 - binary_accuracy: 0.6895 - precision: 0.0782 - recall: 0.5620 - auc: 0.6859 - val_loss: 0.7321 - val_binary_crossentropy: 0.6352 - val_binary_accuracy: 0.6244 - val_precision: 0.0657 - val_recall: 0.6212 - val_auc: 0.6795\n",
      "Epoch 5/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.3886 - binary_crossentropy: 0.5737 - binary_accuracy: 0.6975 - precision: 0.0819 - recall: 0.5763 - auc: 0.7003 - val_loss: 0.7172 - val_binary_crossentropy: 0.6104 - val_binary_accuracy: 0.6371 - val_precision: 0.0670 - val_recall: 0.6112 - val_auc: 0.6811\n",
      "Epoch 6/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.3865 - binary_crossentropy: 0.5625 - binary_accuracy: 0.7066 - precision: 0.0876 - recall: 0.6030 - auc: 0.7232 - val_loss: 0.7420 - val_binary_crossentropy: 0.6269 - val_binary_accuracy: 0.6345 - val_precision: 0.0672 - val_recall: 0.6187 - val_auc: 0.6788\n",
      "Epoch 7/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.3810 - binary_crossentropy: 0.5348 - binary_accuracy: 0.7248 - precision: 0.1018 - recall: 0.6724 - auc: 0.7712 - val_loss: 0.7495 - val_binary_crossentropy: 0.6178 - val_binary_accuracy: 0.6466 - val_precision: 0.0659 - val_recall: 0.5819 - val_auc: 0.6696\n",
      "Epoch 8/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.3495 - binary_crossentropy: 0.4707 - binary_accuracy: 0.7688 - precision: 0.1325 - recall: 0.7682 - auc: 0.8440 - val_loss: 0.6374 - val_binary_crossentropy: 0.5090 - val_binary_accuracy: 0.7538 - val_precision: 0.0780 - val_recall: 0.4654 - val_auc: 0.6700\n",
      "Epoch 9/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.3099 - binary_crossentropy: 0.4128 - binary_accuracy: 0.8100 - precision: 0.1664 - recall: 0.8286 - auc: 0.8908 - val_loss: 0.6191 - val_binary_crossentropy: 0.4932 - val_binary_accuracy: 0.7642 - val_precision: 0.0732 - val_recall: 0.4100 - val_auc: 0.6466\n",
      "Epoch 10/25\n",
      "615/615 [==============================] - 25s 41ms/step - loss: 0.3151 - binary_crossentropy: 0.4181 - binary_accuracy: 0.8190 - precision: 0.1706 - recall: 0.8070 - auc: 0.8876 - val_loss: 0.5509 - val_binary_crossentropy: 0.4279 - val_binary_accuracy: 0.8112 - val_precision: 0.0859 - val_recall: 0.3763 - val_auc: 0.6729\n",
      "Epoch 11/25\n",
      "615/615 [==============================] - 25s 41ms/step - loss: 0.2847 - binary_crossentropy: 0.3735 - binary_accuracy: 0.8408 - precision: 0.1943 - recall: 0.8335 - auc: 0.9113 - val_loss: 0.4820 - val_binary_crossentropy: 0.3790 - val_binary_accuracy: 0.8462 - val_precision: 0.0921 - val_recall: 0.3128 - val_auc: 0.6710\n",
      "Epoch 12/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2496 - binary_crossentropy: 0.3392 - binary_accuracy: 0.8623 - precision: 0.2254 - recall: 0.8750 - auc: 0.9322 - val_loss: 0.4906 - val_binary_crossentropy: 0.3901 - val_binary_accuracy: 0.8465 - val_precision: 0.0919 - val_recall: 0.3115 - val_auc: 0.6654\n",
      "Epoch 13/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2521 - binary_crossentropy: 0.3412 - binary_accuracy: 0.8645 - precision: 0.2280 - recall: 0.8731 - auc: 0.9318 - val_loss: 0.4948 - val_binary_crossentropy: 0.3912 - val_binary_accuracy: 0.8482 - val_precision: 0.0877 - val_recall: 0.2897 - val_auc: 0.6526\n",
      "Epoch 14/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2437 - binary_crossentropy: 0.3330 - binary_accuracy: 0.8693 - precision: 0.2354 - recall: 0.8789 - auc: 0.9366 - val_loss: 0.4626 - val_binary_crossentropy: 0.3657 - val_binary_accuracy: 0.8611 - val_precision: 0.0935 - val_recall: 0.2766 - val_auc: 0.6601\n",
      "Epoch 15/25\n",
      "615/615 [==============================] - 25s 41ms/step - loss: 0.2376 - binary_crossentropy: 0.3258 - binary_accuracy: 0.8737 - precision: 0.2419 - recall: 0.8788 - auc: 0.9397 - val_loss: 0.4552 - val_binary_crossentropy: 0.3611 - val_binary_accuracy: 0.8645 - val_precision: 0.0918 - val_recall: 0.2611 - val_auc: 0.6639\n",
      "Epoch 16/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2286 - binary_crossentropy: 0.3204 - binary_accuracy: 0.8764 - precision: 0.2472 - recall: 0.8861 - auc: 0.9422 - val_loss: 0.4691 - val_binary_crossentropy: 0.3827 - val_binary_accuracy: 0.8520 - val_precision: 0.0888 - val_recall: 0.2841 - val_auc: 0.6526\n",
      "Epoch 17/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2221 - binary_crossentropy: 0.3144 - binary_accuracy: 0.8786 - precision: 0.2511 - recall: 0.8896 - auc: 0.9444 - val_loss: 0.4691 - val_binary_crossentropy: 0.3877 - val_binary_accuracy: 0.8554 - val_precision: 0.0906 - val_recall: 0.2816 - val_auc: 0.6594\n",
      "Epoch 18/25\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.2180 - binary_crossentropy: 0.3139 - binary_accuracy: 0.8792 - precision: 0.2523 - recall: 0.8910 - auc: 0.9450 - val_loss: 0.4161 - val_binary_crossentropy: 0.3347 - val_binary_accuracy: 0.8772 - val_precision: 0.0931 - val_recall: 0.2299 - val_auc: 0.6525\n",
      "Epoch 19/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2195 - binary_crossentropy: 0.3154 - binary_accuracy: 0.8781 - precision: 0.2505 - recall: 0.8909 - auc: 0.9444 - val_loss: 0.4346 - val_binary_crossentropy: 0.3533 - val_binary_accuracy: 0.8732 - val_precision: 0.0957 - val_recall: 0.2498 - val_auc: 0.6642\n",
      "Epoch 20/25\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.2189 - binary_crossentropy: 0.3156 - binary_accuracy: 0.8787 - precision: 0.2515 - recall: 0.8913 - auc: 0.9444 - val_loss: 0.4321 - val_binary_crossentropy: 0.3509 - val_binary_accuracy: 0.8679 - val_precision: 0.0908 - val_recall: 0.2486 - val_auc: 0.6564\n",
      "Epoch 21/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2164 - binary_crossentropy: 0.3109 - binary_accuracy: 0.8791 - precision: 0.2523 - recall: 0.8921 - auc: 0.9458 - val_loss: 0.4469 - val_binary_crossentropy: 0.3669 - val_binary_accuracy: 0.8627 - val_precision: 0.0875 - val_recall: 0.2511 - val_auc: 0.6517\n",
      "Epoch 22/25\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.2131 - binary_crossentropy: 0.3082 - binary_accuracy: 0.8800 - precision: 0.2544 - recall: 0.8958 - auc: 0.9467 - val_loss: 0.4410 - val_binary_crossentropy: 0.3601 - val_binary_accuracy: 0.8662 - val_precision: 0.0922 - val_recall: 0.2579 - val_auc: 0.6512\n",
      "Epoch 23/25\n",
      "615/615 [==============================] - 24s 40ms/step - loss: 0.2146 - binary_crossentropy: 0.3093 - binary_accuracy: 0.8802 - precision: 0.2544 - recall: 0.8946 - auc: 0.9463 - val_loss: 0.4572 - val_binary_crossentropy: 0.3775 - val_binary_accuracy: 0.8627 - val_precision: 0.0923 - val_recall: 0.2679 - val_auc: 0.6596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7226869b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit with class weights\n",
    "kdd12_class_weights = {0: 0.26320222353238437, 1: 4.984051036682616}\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=256,\n",
    "    epochs=25,\n",
    "    callbacks=[\n",
    "        csvLogger,\n",
    "        modelCheckpoint,\n",
    "        earlystopping\n",
    "    ],\n",
    "    class_weight=kdd12_class_weights,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlds_gpu)",
   "language": "python",
   "name": "mlds_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
